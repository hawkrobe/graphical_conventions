{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import pymongo as pm\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','helpers') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','helpers'))\n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import df_generation_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'data')\n",
    "experiment_dir = os.path.join(results_dir,'experiment')\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['graphical_conventions']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName1 = 'run3_size4_waiting'\n",
    "iterationName2 = 'run4_generalization'\n",
    "iterationName3 = 'run5_submitButton_testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## list of researcher mturk worker ID's to ignore\n",
    "jefan = ['A1MMCS8S8CTWKU','A1MMCS8S8CTWKV','A1MMCS8S8CTWKS']\n",
    "hawkrobe = ['A1BOIDKD33QSDK']\n",
    "megsano = ['A1DVQQLVZR7W6I']\n",
    "researchers = jefan + hawkrobe + megsano "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "## run 3 - get total number of stroke and clickedObj events in the collection as a whole\n",
    "S1 = coll.find({ '$and': [{'iterationName':iterationName1}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C1 = coll.find({ '$and': [{'iterationName':iterationName1}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "\n",
    "## run 4 - get total number of stroke and clickedObj events in the collection as a whole\n",
    "S2 = coll.find({ '$and': [{'iterationName':iterationName2}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C2 = coll.find({ '$and': [{'iterationName':iterationName2}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "\n",
    "## run 5 - get total number of stroke and clickedObj events in the collection as a whole\n",
    "S3 = coll.find({ '$and': [{'iterationName':iterationName3}, {'eventType': 'stroke'}]}).sort('time')\n",
    "C3 = coll.find({ '$and': [{'iterationName':iterationName3}, {'eventType': 'clickedObj'}]}).sort('time')\n",
    "\n",
    "print str(S1.count() + S2.count() + S3.count()) + ' stroke records in the database.'\n",
    "print str(C1.count() + C2.count() + C3.count()) + ' clickedObj records in the database.' # previously 722 so 882 ideally "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate group dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "reload(h)\n",
    "## get list of all candidate games\n",
    "games = coll.distinct('gameid')\n",
    "\n",
    "## get list of complete and valid games\n",
    "run3_complete_games = h.get_complete_and_valid_games(games,coll,iterationName1,researchers=researchers, tolerate_undefined_worker=False)\n",
    "run4_complete_games = h.get_complete_and_valid_games(games,coll,iterationName2,researchers=researchers, tolerate_undefined_worker=False)\n",
    "run5_complete_games = h.get_complete_and_valid_games(games,coll,iterationName3,researchers=researchers, tolerate_undefined_worker=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(h)\n",
    "## generate actual dataframe and get only valid games (filtering out games with low accuracy, timeouts)\n",
    "D_run3 = h.generate_dataframe(coll, run3_complete_games, iterationName1, experiment_dir)\n",
    "D_run4 = h.generate_dataframe(coll, run4_complete_games, iterationName2, experiment_dir)\n",
    "D_run5 = h.generate_dataframe(coll, run5_complete_games, iterationName3, experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## filtering outliers \n",
    "D_run3_filtered = h.filter_crazies(D_run3, 'numStrokes')\n",
    "D_run3_filtered = h.filter_crazies(D_run3_filtered, 'numCurvesPerSketch')\n",
    "D_run4_filtered = h.filter_crazies(D_run4, 'numStrokes')\n",
    "D_run4_filtered = h.filter_crazies(D_run4_filtered, 'numCurvesPerSketch')\n",
    "D_run5_filtered = h.filter_crazies(D_run5, 'numStrokes')\n",
    "D_run5_filtered = h.filter_crazies(D_run5_filtered, 'numCurvesPerSketch')\n",
    "\n",
    "# filter out incorrect trials \n",
    "D_run3_correct = D_run3_filtered[D_run3_filtered['outcome'] == True]\n",
    "D_run4_correct = D_run4_filtered[D_run4_filtered['outcome'] == True]\n",
    "D_run5_correct = D_run5_filtered[D_run5_filtered['outcome'] == True]\n",
    "\n",
    "# keep this dataframe and make normalized dataframe for within-subject errors \n",
    "D_run3_normalized = D_run3_correct.copy(deep = True)\n",
    "D_run4_normalized = D_run4_correct.copy(deep = True)\n",
    "D_run5_normalized = D_run5_correct.copy(deep = True)\n",
    "\n",
    "reload(h)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'numStrokes', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'drawDuration', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'numCurvesPerSketch', run3_complete_games)\n",
    "D_run3_normalized = h.grand_mean_normalize(D_run3_normalized, 'meanPixelIntensity', run3_complete_games)\n",
    "\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'numStrokes', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'drawDuration', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'numCurvesPerSketch', run4_complete_games)\n",
    "D_run4_normalized = h.grand_mean_normalize(D_run4_normalized, 'meanPixelIntensity', run4_complete_games)\n",
    "\n",
    "D_run5_normalized = h.grand_mean_normalize(D_run4_normalized, 'numStrokes', run4_complete_games)\n",
    "D_run5_normalized = h.grand_mean_normalize(D_run4_normalized, 'drawDuration', run4_complete_games)\n",
    "D_run5_normalized = h.grand_mean_normalize(D_run4_normalized, 'numCurvesPerSketch', run4_complete_games)\n",
    "D_run5_normalized = h.grand_mean_normalize(D_run4_normalized, 'meanPixelIntensity', run4_complete_games)\n",
    "\n",
    "\n",
    "# writing out data \n",
    "\n",
    "## raw, unfiltered\n",
    "D_run3.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run3', 'raw')))\n",
    "D_run4.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run4', 'raw')))\n",
    "D_run5.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run5', 'raw')))\n",
    "\n",
    "\n",
    "## filtered, but includes correct and incorrect trials \n",
    "D_run3_filtered.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run3', 'filtered')))\n",
    "D_run4_filtered.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run4', 'filtered')))\n",
    "D_run5_filtered.to_csv(os.path.join(csv_dir, 'graphical_conventions_{}_{}.csv'.format('run5', 'filtered')))\n",
    "\n",
    "\n",
    "## filtered, and correct trials only \n",
    "D_run3_correct.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'unnormalized')))\n",
    "D_run4_correct.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'unnormalized')))\n",
    "D_run5_correct.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run5', 'unnormalized')))\n",
    "\n",
    "\n",
    "## filtered, correct trials only, and normalized within subject \n",
    "D_run3_normalized.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'normalized')))\n",
    "D_run4_normalized.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'normalized')))\n",
    "D_run5_normalized.to_csv(os.path.join(csv_dir,'graphical_conventions_{}_{}.csv'.format('run5', 'normalized')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in pre-existing dataframes to get png renders to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run3', 'unnormalized'))\n",
    "D_run3_correct = pd.read_csv(fpath)\n",
    "\n",
    "fpath = os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run4', 'unnormalized'))\n",
    "D_run4_correct = pd.read_csv(fpath)\n",
    "\n",
    "fpath = os.path.join(results_dir,'graphical_conventions_{}_{}.csv'.format('run5', 'unnormalized'))\n",
    "D_run5_correct = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "reload(h)\n",
    "h.save_sketches(D_run3_correct, sketch_dir, 'combined', 'run3')\n",
    "h.save_sketches(D_run4_correct, sketch_dir, 'combined', 'run4')\n",
    "h.save_sketches(D_run5_correct, sketch_dir, 'combined', 'run5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
