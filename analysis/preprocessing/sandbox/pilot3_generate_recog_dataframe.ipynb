{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "\n",
    "import os\n",
    "import urllib, cStringIO\n",
    "\n",
    "import pymongo as pm\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import  matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "stimuli_dir = os.path.join(proj_dir,'stimuli')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'analysis','python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'analysis','python'))\n",
    "    \n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    \n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)   \n",
    "    \n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)       \n",
    "    \n",
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers as h\n",
    "if sys.version_info[0]>=3:\n",
    "    from importlib import reload\n",
    "reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['3dObjects']\n",
    "coll = db['graphical_conventions_recog']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'pilot3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get basic participation stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## list of researchers\n",
    "researchers = ['A4SSYO0HDVD4E', 'A1BOIDKD33QSDK','A1MMCS8S8CTWKU']\n",
    "num_correct_thresh = 0\n",
    "num_catch_correct_thresh = 4\n",
    "\n",
    "## get list of valid sessions with reasonable accuracy\n",
    "workers = coll.find({ '$and': [{'iterationName':iterationName}]}).distinct('workerId')\n",
    "workers = [i for i in workers if len(i)>10 and i not in researchers] ## filter workers\n",
    "print '{} workers performed this task'.format(len(workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get total number of recog events in the collection as a whole\n",
    "top_workers = []\n",
    "catch_passable = []\n",
    "for i,w in enumerate(workers):\n",
    "    print 'Analyzing {} | {} of {}'.format(w,str(i).zfill(3),len(workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time',-1)\n",
    "    if R.count()==45:\n",
    "        num_correct = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':False},{'correct':1}]}).sort('time',-1).count()\n",
    "        num_catch_trial_correct = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':True},{'correct':1}]}).sort('time',-1).count()    \n",
    "        num_catch_trials_shown = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':True}]}).sort('time',-1).count()\n",
    "        catch_passable.append(num_catch_trial_correct)\n",
    "        ## make sure: (1) num correct was higher than thresh, (2) all 5 catch trials showed, \n",
    "        ## (3) catch trials were correct above threshold, and (4) it was a full session \n",
    "        if (num_correct >= num_correct_thresh) & (num_catch_trials_shown==5) & \\\n",
    "            (num_catch_trial_correct >= num_catch_correct_thresh): \n",
    "                top_workers.append(w)\n",
    "        \n",
    "print '{} workers got at least {} experimental trials correct and {} catch trials correct and finished the entire HIT.'.format(len(top_workers),num_correct_thresh, num_catch_correct_thresh)        \n",
    "print '{} workers out of {} who finished the HIT got fewer than the threshold correct.'.format(np.sum(np.array(catch_passable)<num_catch_correct_thresh), len(catch_passable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## check how much to bonus a particular worker via compensation HIT\n",
    "# reallyRun = False\n",
    "# if reallyRun:\n",
    "#     w = ''\n",
    "#     C = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w}]}).sort('time',-1)\n",
    "#     for c in C:\n",
    "#         print c['score'], c['numCorrectSoFar']\n",
    "#         clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### construct group dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load in original refgame data to be able to look up the original trialNum\n",
    "path_to_group_data = os.path.join(csv_dir,'graphical_conventions_group_data_run3run4.csv')\n",
    "O = pd.read_csv(path_to_group_data)\n",
    "\n",
    "## get total number of recog events in the collection as a whole\n",
    "# grab rep & accuracy\n",
    "rep = []\n",
    "correct = []\n",
    "rt = []\n",
    "condition = []\n",
    "orig_correct = []\n",
    "generalization = []\n",
    "target = []\n",
    "distractor1 = []\n",
    "distractor2 = []\n",
    "distractor3 = []\n",
    "orig_gameID = []\n",
    "gameID = []\n",
    "version = [] ## yoked vs. scrambled40 vs. scrambled 10\n",
    "recog_id = []\n",
    "trialNum = []\n",
    "orig_trialNum = []\n",
    "\n",
    "for i,w in enumerate(top_workers):\n",
    "    print 'Now analyzing {} | {} of {}'.format(w,str(i+1).zfill(3), len(top_workers))\n",
    "    clear_output(wait=True)\n",
    "    R = coll.find({ '$and': [{'iterationName':iterationName}, {'workerId': w},{'catch_trial':False}]}).sort('time')\n",
    "    for r in R:        \n",
    "        rep.append(r['repetition'])\n",
    "        correct.append(r['correct'])\n",
    "        rt.append(r['rt'])\n",
    "        condition.append(r['condition'])\n",
    "        if 'outcome' in r.keys():\n",
    "            orig_correct.append(r['outcome'])\n",
    "        else:\n",
    "            orig_correct.append(r['original_correct'])\n",
    "        generalization.append(r['Generalization'])\n",
    "        target.append(r['target'])\n",
    "        distractor1.append(r['distractor1'])\n",
    "        distractor2.append(r['distractor2'])\n",
    "        distractor3.append(r['distractor3'])\n",
    "        orig_gameID.append(r['sketch'].split('_')[0])\n",
    "        gameID.append(r['gameID'])\n",
    "        version.append(r['version'])\n",
    "        recog_id.append(r['recog_id'])\n",
    "        trialNum.append(r['trialNum'])\n",
    "        og = r['sketch'].split('_')[0]\n",
    "        orig_trialNum.append(O[(O['gameID']==og) & \\\n",
    "                               (O['repetition']==r['repetition']) & \\\n",
    "                               (O['target']==r['target']['objectname'])]['trialNum'].values[0])\n",
    "        \n",
    "    \n",
    "### make dataframe\n",
    "X = pd.DataFrame([rep,correct,rt,condition,orig_correct,\\\n",
    "                 generalization,target,distractor1,distractor2,\\\n",
    "                 distractor3,orig_gameID,gameID,version,recog_id,trialNum,\\\n",
    "                 orig_trialNum])\n",
    "X = X.transpose()\n",
    "X.columns = ['repetition','correct','rt','condition', 'orig_correct',\\\n",
    "             'generalization','target','distractor1','distractor2',\\\n",
    "             'distractor3','orig_gameID','gameID','version','recog_id','trialNum',\\\n",
    "             'orig_trialNum']\n",
    "\n",
    "## convert datatypes to numeric\n",
    "X['correct'] = pd.to_numeric(X['correct'])\n",
    "X['rt'] = pd.to_numeric(X['rt'])\n",
    "X['orig_correct'] = pd.to_numeric(X['orig_correct'])\n",
    "    \n",
    "print 'Finished analyzing top workers.'\n",
    "print 'There are {} observation in the dataframe.'.format(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing helper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## function to unroll target, distractor dicts into separate columns\n",
    "def dict2cols(X,item='target'):\n",
    "    '''\n",
    "    X = dataframe containing group data\n",
    "    item = which item column to unroll: target? distractor1? \n",
    "    '''\n",
    "    df = pd.DataFrame.from_dict(X[item]) ## make temporary dataframe with dictionary as main column\n",
    "    df2 = df[item].apply(pd.Series) ## separate into different columns\n",
    "    ## rename to ensure uniqueness\n",
    "    df3 = df2.rename(columns={'objectname': '{}_objectname'.format(item),\\\n",
    "                              'shapenetid': '{}_shapenetid'.format(item),\\\n",
    "                              'url': '{}_url'.format(item)})\n",
    "    X2 = X.join(df3) ## add to original group dataframe\n",
    "    X2.drop(labels=[item],axis=1,inplace=True) ## remove old dictionary column\n",
    "    return X2\n",
    "\n",
    "## now actually apply unrolling function\n",
    "items = ['target','distractor1','distractor2','distractor3']\n",
    "for item in items: \n",
    "    print 'Unrolling {}'.format(item)\n",
    "    clear_output(wait=True)\n",
    "    if item in X.columns:\n",
    "        X = dict2cols(X,item=item)\n",
    "        \n",
    "print 'Finished unrolling item dictionaries into separate columns.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## view recognizability by repetition in tabular form\n",
    "X.groupby(['condition','repetition'])['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## how many games from each version were finished?\n",
    "X.groupby('version')['repetition'].count()/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save out raw version of dataframe\n",
    "X.to_csv(os.path.join(results_dir,'graphical_conventions_recog_data_raw.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check representation of original game data in yoked/scrambled40 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load in dataframe\n",
    "X = pd.read_csv(os.path.join(results_dir,'graphical_conventions_recog_data_raw.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by yoked experiment \n",
    "Y = X[X['version']=='yoked']\n",
    "\n",
    "## which orig_gameIDs got played in yoked?\n",
    "orig_gameIDs_yoked = Counter(Y['orig_gameID']).keys()\n",
    "\n",
    "## how many orig_gameIDs got played in yoked?\n",
    "num_unique_orig_games = len(Counter(Y['orig_gameID']).keys())\n",
    "print '{} original gameIDs appeared in the yoked experiment.'.format(num_unique_orig_games)\n",
    "\n",
    "## how many times did each of the orig_gameIDs that did appear in yoked experiment get played?\n",
    "orig_gameIDs_reps = Counter([int(i/40) for i in Counter(Y['orig_gameID']).values()])\n",
    "for entry in orig_gameIDs_reps.keys():\n",
    "    print '   {} were played {} times in the yoked experiment.'.format(orig_gameIDs_reps[entry],entry)\n",
    "\n",
    "## which original gameIDs not yet represented in the yoked dataset?\n",
    "## load in original group_data\n",
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "O = pd.read_csv(path_to_group_data)\n",
    "orig_gameID_list = list(np.unique(O['gameID']))\n",
    "orig_gameIDs_not_yet_yoked = [i for i in orig_gameID_list if i not in orig_gameIDs_yoked]\n",
    "print 'There are {} original gameIDs that have not yet been played in the yoked experiment.'.format(len(orig_gameIDs_not_yet_yoked))\n",
    "\n",
    "## save out list of gameIDs remaining in the stimuli folder, to allow these to be uploaded as their own dataset\n",
    "## for targeted recruitment\n",
    "if len(orig_gameIDs_not_yet_yoked)>=1:\n",
    "    U = pd.DataFrame(orig_gameIDs_not_yet_yoked)\n",
    "    U.columns = ['gameID']\n",
    "    U.to_csv(os.path.join(stimuli_dir,'orig_gameIDs_remaining_yoked.csv'),index=False)\n",
    "    print 'Saving out this list of gameIDs in the stimuli folder, to allow these to be uploaded as their own dataset for targeted recruitment.'\n",
    "else:\n",
    "    print 'All original gameIDs have appeared in the yoked experiment.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## subset by scrambled40\n",
    "S = X[X['version']=='scrambled40']\n",
    "\n",
    "## how many recog_ids got played in yoked?\n",
    "num_unique_orig_recogids = len(Counter(S['recog_id']).keys())\n",
    "print '{} recog_ids appeared in the scrambled40 experiment.'.format(num_unique_orig_recogids)\n",
    "\n",
    "## which recog_ids got played in scrambled40?\n",
    "recog_ids_scrambled = Counter(S['recog_id']).keys()\n",
    "\n",
    "recog_id_reps = Counter([int(i) for i in Counter(S['recog_id']).values()])\n",
    "for entry in sorted(recog_id_reps.keys()):\n",
    "    print '   {} games appeared {} trials from them appear in the scrambled40 experiment.'.format(recog_id_reps[entry],entry)\n",
    "\n",
    "## which recog_ids remaining?\n",
    "recog_id_list = list(np.unique(O['recog_id']))\n",
    "recog_ids_remaining = [i for i in recog_id_list if i not in recog_ids_scrambled]\n",
    "grouped_recog_ids_remaining = np.unique([np.int64(i/4) for i in recog_ids_remaining])\n",
    "print 'There are still {} grouped_recog_ids to run.'.format(len(grouped_recog_ids_remaining))\n",
    "\n",
    "if len(grouped_recog_ids_remaining)>=1:\n",
    "    U = pd.DataFrame(grouped_recog_ids_remaining)\n",
    "    U.columns = ['grouped_recog_id']\n",
    "    U.to_csv(os.path.join(stimuli_dir,'grouped_recog_ids_remaining_scrambled40.csv'),index=False)\n",
    "    print 'Saving out this list of recogIDs in the stimuli folder, to allow these to be uploaded as their own dataset for targeted recruitment.'\n",
    "else:\n",
    "    print 'All original grouped_recog_ids have appeared in the scrambled40 experiment.'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize recognizability x repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## get dataframe subsetted by condition and broken out by target\n",
    "XR = X[X['condition']=='repeated'].reset_index(drop=True)\n",
    "XR = XR.sort_values(by=['target_objectname'])\n",
    "XR['repetition']=pd.to_numeric(pd.Series(XR['repetition']))\n",
    "targ_list = np.unique(XR.target_objectname.values)\n",
    "\n",
    "## convert post phase control trial repetition indices from 0-->7\n",
    "XC = X[X['condition']=='control'].reset_index(drop=True)\n",
    "XC['repetition'].replace(1,7,inplace=True)\n",
    "XC['repetition']=pd.to_numeric(pd.Series(XC['repetition']))\n",
    "\n",
    "## recombine to form X2\n",
    "X2 = pd.concat([XR,XC],axis=0)\n",
    "\n",
    "## plot recognizability, collapsing across target\n",
    "# fig = plt.figure(figsize=(4,4))\n",
    "fig, ax = plt.subplots()\n",
    "sns.set_context('talk')\n",
    "sns.lineplot(data=XR,x='repetition',y='correct',hue='version',ax=ax)\n",
    "# sns.pointplot(data=X2_,x='repetition',y='correct',hue='version',ax=ax)\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(bbox_to_anchor=(1.7, 0), loc='lower right', ncol=1)\n",
    "\n",
    "## plot recognizability, split out by target\n",
    "split_out_by_target = False\n",
    "if split_out_by_target:\n",
    "    fig = plt.figure(figsize=(16,16))\n",
    "    g = sns.FacetGrid(XR, col=\"target_objectname\", col_wrap=4,height=3, margin_titles=False)\n",
    "    g.map(sns.lineplot, \"repetition\", \"correct\", alpha=.7)\n",
    "    g.set_titles(\"{col_name}\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aggregate with original refgame dataset and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## load in original group_data\n",
    "path_to_group_data = os.path.join(results_dir,'graphical_conventions.csv')\n",
    "O = pd.read_csv(path_to_group_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## aggregate original refgame and recog dataframes\n",
    "## and add some handy additional fields\n",
    "# OR = O[O['condition']=='repeated'].reset_index(drop=True)\n",
    "O = O.rename(columns={'outcome':'correct'})\n",
    "O['logRT'] = np.log(O['drawDuration']*1000)\n",
    "O['version'] = pd.Series(['refgame']*len(O))\n",
    "X2['logRT'] = np.log(X2['rt']) ## add log RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## save out concatenated dataframe for stats\n",
    "_O = O[['version','repetition','gameID','condition','target', 'correct', 'logRT','trialNum']]\n",
    "_O = _O.assign(orig_gameID=_O['gameID']) # create column with same name as in yoked, to allow for paired-game analysis\n",
    "_X2 = X2[['version','repetition','gameID','condition','target_objectname','correct', 'logRT','orig_gameID','trialNum']]\n",
    "_X2.rename({'target_objectname':'target'}, axis='columns',inplace=True)\n",
    "## concatenated original and recog experiments\n",
    "R = pd.concat([_O,_X2],axis=0,sort=False).reset_index()\n",
    "R.to_csv(os.path.join(results_dir,'graphical_conventions_recog_data.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## plot accuracy timecourse\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "## subset by repeated condition for this plot\n",
    "_R = R[R['condition']=='repeated']\n",
    "sns.lineplot(data=_R,x='repetition',y='correct',hue='version')\n",
    "plt.ylim(0,1)\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(loc = 'lower right')\n",
    "t = plt.title('Comparing recognizability in refgame vs. recog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,4))\n",
    "sns.lineplot(data=_R,x='repetition',y='logRT',hue='version')\n",
    "plt.ylim(0,10)\n",
    "plt.yticks(np.arange(0, 10, 1))\n",
    "plt.xticks(np.arange(0, 8, 1))\n",
    "# plt.plot([0,7],[0.25,0.25],color='black',linestyle=':')\n",
    "plt.legend(loc = 'lower right')\n",
    "t = plt.title('Comparing RT in refgame vs. recog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute BIS (z-score within new gameID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zscore(x,mu,sd):\n",
    "    return (x-mu)/(sd+1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sort dataframe by gameID, repetition, and target_objectname\n",
    "X3 = _R.sort_values(by=['gameID','repetition','target']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## groupby gameID\n",
    "grouped = X3.groupby('gameID')\n",
    "\n",
    "## init new aggregated vars\n",
    "acc_norm = []\n",
    "rt_norm = []\n",
    "bis = []\n",
    "gameID = []\n",
    "orig_gameID = []\n",
    "repetition = []\n",
    "version = []\n",
    "rep1_acc = []\n",
    "rep1_rt = []\n",
    "rep1_bis = []\n",
    "trialNum = []\n",
    "\n",
    "## loop through games\n",
    "for name, group in grouped:\n",
    "    print 'Analyzing {}'.format(name)\n",
    "    clear_output(wait=True)\n",
    "    rt_mu = group['logRT'].mean()\n",
    "    rt_sd = group['logRT'].std()    \n",
    "    acc_mu = group['correct'].mean()\n",
    "    acc_sd = group['correct'].std()    \n",
    "    \n",
    "    #repwise = group.groupby('repetition')\n",
    "    ## record rep1_bis\n",
    "    rep1 = group[group['repetition']==0]\n",
    "    rep_acc_raw = rep1['correct'].mean()\n",
    "    rep_rt_raw = rep1['logRT'].mean()             \n",
    "    _rep1_acc = zscore(rep_acc_raw,acc_mu,acc_sd)\n",
    "    _rep1_rt = zscore(rep_rt_raw,rt_mu,rt_sd)\n",
    "    _rep1_bis = _rep1_acc - _rep1_rt \n",
    "    \n",
    "    ## loop through trials within games\n",
    "    trialwise = group.groupby('trialNum')    \n",
    "    for trialname,trial in trialwise:            \n",
    "        accN = zscore(trial['correct'].values[0],acc_mu,acc_sd)\n",
    "        rtN = zscore(trial['logRT'].values[0],rt_mu,rt_sd)\n",
    "        acc_norm.append(accN)\n",
    "        rt_norm.append(rtN)\n",
    "        bis.append(accN-rtN)        \n",
    "        rep1_acc.append(_rep1_acc)\n",
    "        rep1_rt.append(_rep1_rt)\n",
    "        rep1_bis.append(_rep1_bis)\n",
    "        gameID.append(trial['gameID'].values[0])\n",
    "        orig_gameID.append(trial['orig_gameID'].values[0])\n",
    "        repetition.append(trial['repetition'].values[0])\n",
    "        version.append(trial['version'].values[0])\n",
    "        trialNum.append(trialname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## construct summary dataframe (aggregates within repetition)\n",
    "X4 = pd.DataFrame([gameID,orig_gameID,repetition,acc_norm,\\\n",
    "                   rt_norm,bis,rep1_bis,version,trialNum])\n",
    "X4 = X4.transpose()\n",
    "X4.columns = ['gameID','orig_gameID','repetition','acc_norm',\\\n",
    "              'rt_norm','bis','bis_baseline','version','trialNum']\n",
    "\n",
    "## convert to numeric datatype\n",
    "X4['bis']=pd.to_numeric(pd.Series(X4['bis']))\n",
    "X4['bis_baseline']=pd.to_numeric(pd.Series(X4['bis_baseline']))\n",
    "X4['acc_norm']=pd.to_numeric(pd.Series(X4['acc_norm']))\n",
    "X4['rt_norm']=pd.to_numeric(pd.Series(X4['rt_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## visualize BIS x repetition\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.lineplot(data=X4,x='repetition',y='bis',hue='version',ci=95)\n",
    "plt.ylim(-1.5,1),\n",
    "t = plt.yticks(np.arange(-1.6, 1.1, 0.5))\n",
    "t = plt.xticks(np.arange(0, 8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## baseline bis against first rep\n",
    "X4['bis_relative'] = X4['bis']-X4['bis_baseline']\n",
    "X4['repetition_1'] = X4['repetition'] + 1 \n",
    "## save it out \n",
    "X4.to_csv(os.path.join(results_dir,'graphical_conventions_recog_data_bis.csv'),index=False)\n",
    "\n",
    "## plot it\n",
    "colors = sns.color_palette(\"cubehelix\", 4)[:3]\n",
    "sns.set_style('white')\n",
    "sns.set_style('ticks')\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.lineplot(data=X4,x='repetition_1',y='bis_relative',hue='version',palette=colors)\n",
    "plt.ylim(0.,2.5)\n",
    "t = plt.yticks(np.arange(0., 2.6, 0.5))\n",
    "t = plt.xticks(np.arange(1, 9, 1))\n",
    "plt.legend(bbox_to_anchor=(1.7, 0), loc='lower right', ncol=1)\n",
    "t = plt.ylabel('relative efficiency')\n",
    "t = plt.xlabel('repetition')\n",
    "\n",
    "out_path = os.path.join(results_dir,'plots','recog_BIS_timeseries_seaborn.pdf')\n",
    "fig.savefig(out_path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rgb2hex(rgb_tuple):\n",
    "    return '#%02x%02x%02x' % tuple([i*256 for i in rgb_tuple])\n",
    "print 'Colors to use in ggplot are: '\n",
    "print [rgb2hex(i) for i in colors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
