{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "## add helpers to python path\n",
    "if os.path.join('..','helpers') not in sys.path:\n",
    "    sys.path.append(os.path.join('..','helpers'))\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter\n",
    "import object_mask_utils as u\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "from skimage import io, img_as_float\n",
    "import base64\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'data')\n",
    "csv_dir = os.path.join(results_dir,'diagnosticity')\n",
    "sketch_dir = os.path.abspath(os.path.join(csv_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(csv_dir,'gallery'))\n",
    "map_dir = os.path.abspath(os.path.join(csv_dir,'maps'))\n",
    "mask_dir = os.path.join(csv_dir, 'object_masks')\n",
    "datavol_dir = os.path.join('/data/datasets/semantic_mapping') # the specific path used on nightingale.ucsd.edu\n",
    "data_dir = datavol_dir if socket.gethostname()=='nightingale' else csv_dir\n",
    "\n",
    "## import dictionaries that map between shapenet ids and graphical conventions naming scheme\n",
    "importlib.reload(u)\n",
    "G2S = u.GC2SHAPENET\n",
    "S2G = u.SHAPENET2GC\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "def clear_dir(path_to_dir, ext = 'png'):\n",
    "    files = glob.glob(os.path.join(path_to_dir, '*'))\n",
    "    if len(files) > 0:\n",
    "        for f in files:\n",
    "            if f.split('.')[-1]==ext:\n",
    "                os.remove(f)\n",
    "        print('Deleted {} {} files in {}'.format(ext, len(files), path_to_dir))\n",
    "    else:\n",
    "        print('{} already empty. Did not delete any files.'.format(path_to_dir))\n",
    "    return path_to_dir\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(i) for i in [results_dir,csv_dir,sketch_dir,gallery_dir, map_dir, mask_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get object masks\n",
    "\n",
    "People often annotated outside the boundaries of the actual object, so we use a segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from objects import *\n",
    "\n",
    "## convert dict to list\n",
    "object_list = [shapenet_30afd2ef2ed30238aa3d0a2f00b54836,shapenet_30dc9d9cfbc01e19950c1f85d919ebc2,shapenet_4c1777173111f2e380a88936375f2ef4,\n",
    "shapenet_3466b6ecd040e252c215f685ba622927,shapenet_38f87e02e850d3bd1d5ccc40b510e4bd,shapenet_3cf6db91f872d26c222659d33fd79709,\n",
    "shapenet_3d7ebe5de86294b3f6bcd046624c43c9,shapenet_56262eebe592b085d319c38340319ae4,shapenet_1d1641362ad5a34ac3bd24f986301745,shapenet_1da9942b2ab7082b2ba1fdc12ecb5c9e,shapenet_2448d9aeda5bb9b0f4b6538438a0b930,\n",
    "shapenet_23b0da45f23e5fb4f4b6538438a0b930,shapenet_2b5953c986dd08f2f91663a74ccd2338,shapenet_2e291f35746e94fa62762c7262e78952,\n",
    "shapenet_2eaab78d6e4c4f2d7b0c85d2effc7e09,shapenet_309674bdec2d24d7597976c675750537]\n",
    "\n",
    "## convert list of dicts to pd dataframe\n",
    "O = pd.DataFrame(object_list)\n",
    "\n",
    "this_url = O.url.values[0]\n",
    "\n",
    "for i,d in O.iterrows():\n",
    "\n",
    "    ## get image data from URL\n",
    "    response = requests.get(d['url'])\n",
    "    img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "    ## find zero pixels and convert to object mask\n",
    "    nonzeros = np.array(img)!=0\n",
    "    _mask = nonzeros.astype(np.uint8).mean(2)*255\n",
    "    mask = Image.fromarray(_mask).convert('L')\n",
    "\n",
    "    ## save out mask to mask_dir\n",
    "    fname = d['subordinate'] + '-mask.png'\n",
    "    out_path = os.path.join(mask_dir, fname)\n",
    "    mask.save(out_path) \n",
    "    print('{} | Saved out mask for {}!'.format(i+1, d['subordinate']))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in annotations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Reproducibility note for internal use only_: If you haven't already run the [`generate_diagnosticity_dataframe.py` script](https://github.com/hawkrobe/graphical_conventions/blob/master/analysis/preprocessing/generate_diagnosticity_dataframe.py) locally, do so. Once you're on `nightingale.ucsd.edu`, run it again to make sure that the annotations are copied to the data dir. `nightingale.ucsd.edu` is the name of the specific compute server used for this project, but is not strictly necessary for others to reproduce our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in data\n",
    "T = pd.read_csv(os.path.join(csv_dir,'refgame2.0/semantic_mapping_annotations_stroke.csv'),\n",
    "               usecols=['paintCanvasPng','svgString', 'condition','repetition','gameID','targetID', 'annotatorID','wID'])\n",
    "\n",
    "## add sketch_id column\n",
    "T = (T.assign(sketch_id = T.apply(lambda x: \n",
    "    '{}_{}_{}'.format(x['gameID'], x['targetID'], str(x['repetition']).zfill(2)),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## invalid/blocked workerIDs who scribbled\n",
    "invalid_workers = (['A1GKV6YWBQ8VU2', 'AFER5ZUTHAA5M', 'A19KUUI9FWPER6'] + ['A52B9HB6G1FYG', 'A2V290GUKCNFSX'] +\n",
    "                   ['ADYFSE3TOTPLK', 'A1SPEUF3LGOF5M', 'A3NH7YCJLJX082', 'A26T013OSL4VI2', 'A2TZ71UUY1HGH3'] + \n",
    "                   ['A3739TTTJN07Z1', 'AMFQAV2CMCQMA', 'A1T3QUEIJ36AO6', 'A18T7E73TNGOKP', 'A2SWFKGQWUXU5N'] +\n",
    "                   ['A2UHVW63V1CMD1', 'AKJ0CNE25NWIQ', 'A2NILISO17LNTJ', 'A2R20ADYVQD4X', 'AFV9LYFT59I2C'] + \n",
    "                   ['A33QMMCDIGGVAE', 'A3NF12KB859RHP', 'A29YJJRBSB7D8I', 'A2B1ER0536RFHF', 'ADS9U0CVXT2IE'] + \n",
    "                   ['A4M35GKK07AAS', 'A1OJZLO9E8Y0VB', 'A1LBXBV4KZ952A', 'A1ZHU7I53TTA5B', 'AHJJUX96EATA7']+\n",
    "                   ['A2S3MMTULJT6R4', 'A1V4ASA56A0WHR'])\n",
    "\n",
    "\n",
    "## single invalid sketch annotations\n",
    "# invalid_sketchIDs = ['7741-1061961c-2778-483e-97de-15fc47b71ca5_waiting_07_07']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show me invalid worker stats\n",
    "showMeInvalids = False\n",
    "if showMeInvalids:\n",
    "    cumulative_invalid_sketches = 0\n",
    "    for i,this_workerID in enumerate(invalid_workers):\n",
    "        ## what else has this worker annotated?\n",
    "        this_workers_annotations = T[(T['wID']==this_workerID)]['sketch_id'].unique()\n",
    "        cumulative_invalid_sketches += len(this_workers_annotations)\n",
    "        print(' {} | {} | This person annotated {} sketches.'.format(str(i+1).zfill(2), this_workerID, len(this_workers_annotations)))\n",
    "    print('In total, they contributed {} invalid sketch annotations.'.format(cumulative_invalid_sketches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22755 records in T.\n",
      "These came from 65 different refgames.\n",
      "These came from 311 different annotation assignments.\n",
      "These came from 278 different worker IDs.\n",
      "18056 of these came are from the repeated condition.\n",
      "4699 of these came are from the control condition.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22755 entries, 0 to 32950\n",
      "Columns: 9 entries, svgString to sketch_id\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 122.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## filter out invalids\n",
    "T = T[~T['wID'].isin(invalid_workers)]\n",
    "# T = T[~T['sketch_id'].isin(invalid_sketchIDs)]\n",
    "\n",
    "print('There are {} records in T.'.format(T.shape[0]))    \n",
    "print('These came from {} different refgames.'.format(T.gameID.nunique()))\n",
    "print('These came from {} different annotation assignments.'.format(T.annotatorID.nunique()))\n",
    "print('These came from {} different worker IDs.'.format(T.wID.nunique()))\n",
    "print('{} of these came are from the repeated condition.'.format(T[T['condition']=='repeated'].shape[0]))\n",
    "print('{} of these came are from the control condition.'.format(T[T['condition']=='control'].shape[0]))\n",
    "print(T.info(verbose=False,memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manually check for invalid annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at sketch map renderings to detect irregularities & scribbles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person annotated 0 sketches.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "## which potentially problematic workerID?\n",
    "this_workerID = 'A1V4ASA56A0WHR'\n",
    "\n",
    "showThis = True\n",
    "if showThis:\n",
    "    ## what else has this worker annotated?\n",
    "    this_workers_annotations = T[(T['wID']==this_workerID)]['sketch_id'].unique()\n",
    "    print('This person annotated {} sketches.'.format(len(this_workers_annotations)))\n",
    "    print(sorted(this_workers_annotations))\n",
    "    for this_sketchID in sorted(this_workers_annotations):\n",
    "        display(Image.open(os.path.join(sketch_dir, '{}.png'.format(this_sketchID))))\n",
    "        display(Image.open(os.path.join(single_sketch_map_dir, '{}.png'.format(this_sketchID))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### divide CSV data into batches to ease image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Saved 52 batches in total.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(u)\n",
    "\n",
    "annotations_stroke_batch_dir = os.path.join(data_dir, 'refgame2.0','semantic_mapping_annotations_stroke_batches')\n",
    "## divide CSV data into batches to ease image processing\n",
    "sketch_ids = T.sketch_id.unique()\n",
    "for i,curr_batch in enumerate(u.batch(sketch_ids, 50)):\n",
    "    t = T[T['sketch_id'].isin(curr_batch)]\n",
    "    out_path = os.path.join(annotations_stroke_batch_dir,'semantic_mapping_annotations_stroke_batch{}.csv'.format(i))\n",
    "    t.to_csv(out_path)\n",
    "    print('Saved batch to {}'.format(out_path))\n",
    "    clear_output(wait=True)\n",
    "print('Done! Saved {} batches in total.'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now iterate through batches of dataset and apply image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (T_batch) :\n",
    "    start = time.time()\n",
    "\n",
    "    ## apply preprocessing to get base heatmaps\n",
    "    ims = T_batch.apply(lambda x: Image.open(BytesIO(base64.b64decode(x['paintCanvasPng']))), axis=1)\n",
    "#     print('Finished converting png strings to PIL Images. {} seconds elapsed.'.format((time.time() - start)))        \n",
    "    T_batch = T_batch.assign(imsb = ims.apply(lambda x: x.convert('RGB')))\n",
    "#     print('Finished converting to RGB. {} seconds elapsed.'.format(np.round(time.time() - start,3)))            \n",
    "    T_batch = T_batch.assign(arrs = T_batch['imsb'].apply(lambda x: np.array(x).astype(np.uint16)))\n",
    "#     print('Finished adding image arrays to big dataframe. {} seconds elapsed.'.format(time.time() - start))\n",
    "    \n",
    "    # Filter out invalid imsizes & empty rows\n",
    "    T_batch = T_batch.assign(valid_imsize = T_batch.apply(lambda x: True if x['arrs'].shape[0]==300 else False, axis=1))    \n",
    "    T_batch = T_batch.assign(empty_annotation = T_batch.apply(lambda x: x['arrs'].flatten().sum() == 0, axis=1))    \n",
    "    T_batch = T_batch[T_batch['valid_imsize'] == True]\n",
    "    T_batch = T_batch[T_batch['empty_annotation'] != True]\n",
    "    \n",
    "    ## add identifier for (target, rep) combinations\n",
    "    T_batch = T_batch.assign(target_rep = T_batch.apply(lambda x: '{}_{}'.format(x['targetID'], str(x['repetition']).zfill(2)), axis=1))\n",
    "#     print('Finished filtering for valid images.')\n",
    "    end = time.time()\n",
    "#     print('{} seconds elapsed for image preprocessing.'.format(np.round(end-start,3)))\n",
    "    return T_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted png 2600 files in /Users/judithfan/graphical_conventions/data/diagnosticity/maps/single_sketch_maps\n"
     ]
    }
   ],
   "source": [
    "## create dirs that do not already exist\n",
    "single_sketch_map_dir = os.path.join(map_dir,'single_sketch_maps')\n",
    "targetRep_sketch_map_dir = os.path.join(map_dir,'targetRep_sketch_maps')\n",
    "result = [make_dir_if_not_exists(i) for i in [single_sketch_map_dir, targetRep_sketch_map_dir]]\n",
    "\n",
    "## clear single sketch map dir\n",
    "folder = clear_dir(single_sketch_map_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "### load in chunks of dataframe at a time to do all preprocessing\n",
    "batch_paths = [os.path.join(annotations_stroke_batch_dir,i) for i in os.listdir(annotations_stroke_batch_dir) if i.split('_')[-1][:5]=='batch']\n",
    "\n",
    "K = 10\n",
    "for N in np.arange(1,K+1):\n",
    "    A = dict()\n",
    "    for batch_ind, path in enumerate(batch_paths):\n",
    "        T_batch = preprocess(pd.read_csv(path))\n",
    "\n",
    "        ## create H dictionary for each target and repetition for EACH REFGAME PARTICIPANT\n",
    "        H = dict()\n",
    "        for name, group in T_batch.groupby(['target_rep','gameID']):\n",
    "            ## subset group to only include single annotation session?\n",
    "            if len(group['annotatorID'].unique()) > 1:\n",
    "                _arr = group['annotatorID'].unique() ## get unique annotation assignment ID's\n",
    "                arr = _arr[~pd.isnull(_arr)] ## remove nans\n",
    "\n",
    "                ## get annotatorID with the most records                \n",
    "                thorough_annotatorID = max(Counter(group['annotatorID']).items(), key=operator.itemgetter(1))[0] \n",
    "                group_subset = group[group['annotatorID']==thorough_annotatorID]  \n",
    "            else:\n",
    "                group_subset = group\n",
    "\n",
    "            ## exploratory: subset to first N/K fraction of strokes \n",
    "            ## question: how does diagnosticity change as function of cumulative amount of sketch completed?                \n",
    "            num_early_strokes_included = np.int(np.ceil(N*group_subset.shape[0]/K))\n",
    "            group_subset = group_subset[:num_early_strokes_included]\n",
    "            if N==K:\n",
    "                single_subsketch_map_dir = os.path.join(map_dir,'single_sketch_maps')\n",
    "            else:\n",
    "                single_subsketch_map_dir = os.path.join(map_dir,'single_subsketch_maps_{}_{}'.format(N,K))\n",
    "                \n",
    "            make_dir_if_not_exists(single_subsketch_map_dir)\n",
    "\n",
    "\n",
    "            ## init dictionary     \n",
    "            if not name[0] in H.keys():\n",
    "                H[name[0]] = dict()\n",
    "\n",
    "            ## stack arrays to form a single composite image, taking max value over any spatial position\n",
    "            combined = np.amax(np.stack(np.array(group_subset['arrs']),axis=3), axis=3)\n",
    "            \n",
    "            ## load in object mask and cross with sketch map\n",
    "            targetID = '_'.join(name[0].split('_')[:2])\n",
    "            mask_path = os.path.join(mask_dir, '{}-mask.png'.format(targetID))\n",
    "            object_mask = Image.open(mask_path).resize((300,300),Image.LANCZOS)            \n",
    "            combined_masked = combined.astype(np.float32).mean(2) * object_mask / 255\n",
    "            \n",
    "            ## convert to binary PIL image and store in dictionary H \n",
    "            H[name[0]][name[1]] = (Image.fromarray(u.binarize_vec((u.minmaxnorm(combined_masked) * 255))\n",
    "                                      .astype(np.uint8))\n",
    "                                      .convert('1'))                              \n",
    "            # record num annotations per sketch\n",
    "            A['{}_{}'.format(name[1], name[0])] =  len(np.unique(group_subset['annotatorID'].values))\n",
    "            # save image out as PNG to main single sketch map dir\n",
    "            out_path = os.path.join(single_sketch_map_dir,'{}_{}.png'.format(name[1],name[0]))\n",
    "            H[name[0]][name[1]].save(out_path)\n",
    "            # also save out to another path, in subsketch map dir\n",
    "            out_path_N_K = os.path.join(single_subsketch_map_dir,'{}_{}.png'.format(name[1],name[0]))\n",
    "            H[name[0]][name[1]].save(out_path_N_K)        \n",
    "\n",
    "            print('{}/{} | batch {} of {} | Saved out PNG for {} from {}'.format(N,K,batch_ind, len(batch_paths), name[0], name[1]))       \n",
    "            clear_output(wait=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now get average heatmap, collapsing over annotators within a target/repetition combination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/judithfan/graphical_conventions/data/diagnosticity/maps/single_subsketch_maps_10_10/5947-794501d9-b90d-4151-a7c9-149c399c5df3_dining_00_00.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gl/tf1l1j554s186d_crpz71bw80000gn/T/ipykernel_17554/18016549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gl/tf1l1j554s186d_crpz71bw80000gn/T/ipykernel_17554/18016549.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mthis_targ\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/judithfan/graphical_conventions/data/diagnosticity/maps/single_subsketch_maps_10_10/5947-794501d9-b90d-4151-a7c9-149c399c5df3_dining_00_00.png'"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "for N in np.arange(1,K+1):\n",
    "\n",
    "    S = [os.path.join(map_dir,'single_subsketch_maps_{}_{}'.format(N,K),i) for i in os.listdir(single_sketch_map_dir)]\n",
    "    assert len(np.unique(['_'.join(i.split('_')[-3:]) for i in S])) == 16*8\n",
    "    target_reps = np.unique(['_'.join(i.split('_')[-3:]).split('.')[0] for i in S])\n",
    "    G = dict()\n",
    "\n",
    "    for tr,this_targ in enumerate(target_reps):\n",
    "        G[this_targ] = dict()    \n",
    "        matches = [i for i in S if '_'.join(i.split('_')[-3:])==this_targ+'.png']\n",
    "        avg = np.mean(np.array([np.array(Image.open(match)) for match in matches]), axis=0) * 255\n",
    "        G[this_targ]['target'] = '_'.join(this_targ.split('_')[:2])\n",
    "        G[this_targ]['layers'] = len(matches)\n",
    "        im = (Image.fromarray(avg.astype(np.uint16))\n",
    "                                          .convert('L'))\n",
    "        # save image out as PNG\n",
    "        if N==K:\n",
    "            out_dir = os.path.join(map_dir, 'targetRep_sketch_maps')\n",
    "        else:\n",
    "            out_dir = os.path.join(map_dir, 'targetRep_subsketch_maps_{}_{}'.format(N,K))\n",
    "        make_dir_if_not_exists(out_dir)\n",
    "        out_path = os.path.join(out_dir,'{}.png'.format(this_targ))\n",
    "\n",
    "        im.save(out_path)\n",
    "        print('{} of {} |Saved out PNG for {}'.format(tr,len(target_reps),this_targ))\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "# save out metadata    \n",
    "out_path = os.path.join(map_dir,'targetRep_map_meta.js')\n",
    "with open(out_path, 'w') as fout:\n",
    "    json.dump(G, fout)    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## render heat map gallery\n",
    "importlib.reload(u)\n",
    "with open(os.path.join(map_dir,'targetRep_map_meta.js')) as f:\n",
    "    G = json.load(f)\n",
    "u.render_heatmap_gallery(G, gallery_dir = gallery_dir, \n",
    "                         data_dir = '../../data/diagnosticity/maps/targetRep_sketch_maps',\n",
    "                         num_reps = 8, \n",
    "                         show_fig = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
