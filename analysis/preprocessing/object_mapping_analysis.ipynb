{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "## add helpers to python path\n",
    "if os.path.join('..','helpers') not in sys.path:\n",
    "    sys.path.append(os.path.join('..','helpers'))\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageFilter\n",
    "import object_mask_utils as u\n",
    "import socket\n",
    "import glob\n",
    "\n",
    "from skimage import io, img_as_float\n",
    "import base64\n",
    "\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import importlib\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "import operator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('../../')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'data')\n",
    "csv_dir = os.path.join(results_dir,'diagnosticity')\n",
    "sketch_dir = os.path.abspath(os.path.join(csv_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(csv_dir,'gallery'))\n",
    "map_dir = os.path.abspath(os.path.join(csv_dir,'maps'))\n",
    "mask_dir = os.path.join(csv_dir, 'object_masks')\n",
    "\n",
    "\n",
    "## import dictionaries that map between shapenet ids and graphical conventions naming scheme\n",
    "importlib.reload(u)\n",
    "G2S = u.GC2SHAPENET\n",
    "S2G = u.SHAPENET2GC\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "def clear_dir(path_to_dir, ext = 'png'):\n",
    "    files = glob.glob(os.path.join(path_to_dir, '*'))\n",
    "    if len(files) > 0:\n",
    "        for f in files:\n",
    "            if f.split('.')[-1]==ext:\n",
    "                os.remove(f)\n",
    "        print('Deleted {} {} files in {}'.format(ext, len(files), path_to_dir))\n",
    "    else:\n",
    "        print('{} already empty. Did not delete any files.'.format(path_to_dir))\n",
    "    return path_to_dir\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(i) for i in [results_dir,csv_dir,sketch_dir,gallery_dir, map_dir, mask_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in annotations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1921 records in T.\n",
      "These came from 125 different refgames.\n",
      "These came from 117 different annotation assignments.\n",
      "These came from 110 different worker IDs.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1921 entries, 0 to 1920\n",
      "Columns: 18 entries, _id to wID\n",
      "dtypes: float64(3), int64(4), object(11)\n",
      "memory usage: 15.9 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "T = pd.read_csv(os.path.join(csv_dir,'refgame2.0/semantic_mapping_annotations_object.csv'))\n",
    "print('There are {} records in T.'.format(T.shape[0]))    \n",
    "print('These came from {} different refgames.'.format(T.gameid.nunique()))\n",
    "print('These came from {} different annotation assignments.'.format(T.aID.nunique()))\n",
    "print('These came from {} different worker IDs.'.format(T.wID.nunique()))\n",
    "print(T.info(verbose=False,memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get average heatmap for each pair of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_pair_map_dir = os.path.join(map_dir,'object_pair_maps')\n",
    "pair_gallery_dir = os.path.join(gallery_dir,'object_pair_gallery')\n",
    "target_map_dir = os.path.join(map_dir,'target_object_maps')\n",
    "target_gallery_dir = os.path.join(gallery_dir,'target_object_gallery')\n",
    "result = [make_dir_if_not_exists(i) for i in [object_pair_map_dir, target_map_dir, pair_gallery_dir, target_gallery_dir]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.031 seconds elapsed for extracting diagnosticity maps for each object pair.\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "## apply preprocessing to get base heatmaps\n",
    "ims = T.apply(lambda x: Image.open(BytesIO(base64.b64decode(x['paintCanvasPng']))), axis=1)\n",
    "print('Finished converting png strings to PIL Images. {} seconds elapsed.'.format(np.round(time.time() - start,3)))\n",
    "imsb = ims.apply(lambda x: x.convert('RGB'))\n",
    "print('Finished converting to RGB. {} seconds elapsed.'.format(np.round(time.time() - start,3)))\n",
    "## add arrays to the big T dataframe\n",
    "T = T.assign(arrs = imsb.apply(lambda x: np.array(x).astype(np.uint16)))\n",
    "T = T.assign(valid_imsize = T.apply(lambda x: True if x['arrs'].shape[0]==300 else False, axis=1))\n",
    "print('Finished adding image arrays to big dataframe. {} seconds elapsed.'.format(np.round(time.time() - start,3)))\n",
    "## filter for images that have correct image size (300x300)\n",
    "T = T[T['valid_imsize']==True]\n",
    "## add identifier for (context_id, pair_id) combinations\n",
    "T['target_id'] = T.apply(lambda x: x['targetChair'].split('/')[-1].split('.')[0],axis=1)\n",
    "T['foil_id'] = T.apply(lambda x: x['comparisonChair'].split('/')[-1].split('.')[0],axis=1)\n",
    "T = T.assign(context_target_foil = (T.apply(lambda x: '{}_{}_{}'\n",
    "                                                 .format(x['context_id'],x['target_id'], x['foil_id']), axis=1)))\n",
    "end = time.time()\n",
    "print('{} seconds elapsed for image preprocessing.'.format(np.round(end-start,3)))\n",
    "\n",
    "# NB:\n",
    "# For each context containing 4 chairs, 6 pairs x 2 directions = 12 directed pairs\n",
    "# x 4 contexts (diningA, diningB, waitingA, waitingB) \n",
    "# = 48 context_target_foils\n",
    "\n",
    "## create H dictionary for each context_target_foil (each pair of objects)\n",
    "H = dict() # diagnosticity map for this pair of objects\n",
    "A = dict() # number of times this pair was annotated\n",
    "for name, group in T.groupby('context_target_foil'):\n",
    "    print('Extracting diagnosticity map for {}'.format(name))\n",
    "    combined = np.mean(np.stack(np.array(group['arrs']),axis=3), axis=3)\n",
    "    A[name] = group.shape[0]\n",
    "    H[name] = (Image.fromarray((u.minmaxnorm(combined) * 255)\n",
    "                              .astype(np.uint8))\n",
    "                              .filter(ImageFilter.GaussianBlur(radius=1))\n",
    "                              .convert('L')) \n",
    "    \n",
    "    # save images out as PNG\n",
    "    out_path = os.path.join(object_pair_map_dir,'{}.png'.format(name))\n",
    "    H[name].save(out_path)\n",
    "    clear_output(wait=True)    \n",
    "    \n",
    "end = time.time()\n",
    "print('{} seconds elapsed for extracting diagnosticity maps for each object pair.'.format(np.round(end-start,3)))    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## render gallery of object-pair-level diagnosticity maps\n",
    "importlib.reload(u)\n",
    "u.render_object_pair_gallery(object_pair_map_dir, pair_gallery_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "## now consolidate context_target_foil maps into single map for each target, J\n",
    "\n",
    "## re-convert H into dataframe to make it easier to group by target\n",
    "D = pd.DataFrame.from_dict(H, orient='index').reset_index()\n",
    "D.columns=['context_target_foil','image']\n",
    "D = D.assign(target = D.apply(lambda x: x['context_target_foil'].split('_')[1], axis=1))\n",
    "\n",
    "## create J dict, that contains consolidated target diagnosticity maps\n",
    "J = dict()\n",
    "for name, group in D.groupby('target'):\n",
    "    group = group.assign(arrs = group.apply(lambda x: np.array(x['image']).astype(np.uint16), axis=1))\n",
    "    combined = np.mean(np.stack(np.array(group['arrs']),axis=2), axis=2)\n",
    "    J[name] = (Image.fromarray((u.minmaxnorm(combined) * 255)\n",
    "                              .astype(np.uint8))\n",
    "                              .filter(ImageFilter.GaussianBlur(radius=1))\n",
    "                              .convert('L'))   \n",
    "    \n",
    "    # save images out as PNG\n",
    "    out_path = os.path.join(target_map_dir,'{}.png'.format(S2G[name]))\n",
    "    J[name].save(out_path)\n",
    "    print('Saved out PNG for {}'.format(name))\n",
    "    clear_output(wait=True)    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(u)\n",
    "u.render_target_map_gallery(target_map_dir, target_gallery_dir)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
